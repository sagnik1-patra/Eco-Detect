{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba8caa8-38f6-4784-a602-06d0261a8a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 19:58:41,711 | INFO | [PLOT] Saved accuracy graph → C:\\Users\\sagni\\Downloads\\Eco Detect\\accuracy_curve.png\n",
      "2025-09-02 19:58:41,715 | INFO | Target for plots: trend\n",
      "2025-09-02 19:58:41,718 | INFO | [NaN repair] 'trend': 10 → 0 remaining after interpolation.\n",
      "2025-09-02 19:58:42,089 | INFO | [VAL] R2=0.1100 | RMSE=14.7768 | MAE=7.2493\n",
      "2025-09-02 19:58:42,097 | INFO | [SAVE] Residuals CSV → C:\\Users\\sagni\\Downloads\\Eco Detect\\residuals_full.csv\n",
      "2025-09-02 19:58:42,828 | INFO | [PLOT] Saved residual heatmap → C:\\Users\\sagni\\Downloads\\Eco Detect\\residual_heatmap.png\n",
      "2025-09-02 19:58:43,036 | INFO | [PLOT] Saved predicted vs actual → C:\\Users\\sagni\\Downloads\\Eco Detect\\pred_vs_actual.png\n",
      "2025-09-02 19:58:43,037 | INFO | === DONE (plots) ===\n",
      "2025-09-02 19:58:43,038 | INFO | - C:\\Users\\sagni\\Downloads\\Eco Detect\\accuracy_curve.png\n",
      "2025-09-02 19:58:43,038 | INFO | - C:\\Users\\sagni\\Downloads\\Eco Detect\\residual_heatmap.png\n",
      "2025-09-02 19:58:43,039 | INFO | - C:\\Users\\sagni\\Downloads\\Eco Detect\\pred_vs_actual.png\n",
      "2025-09-02 19:58:43,039 | INFO | - C:\\Users\\sagni\\Downloads\\Eco Detect\\residuals_full.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# ---------------------------\n",
    "# Paths (match the training script)\n",
    "# ---------------------------\n",
    "DATA_CSV   = r\"C:\\Users\\sagni\\Downloads\\Eco Detect\\archive\\goal15.forest_shares.csv\"\n",
    "OUT_DIR    = r\"C:\\Users\\sagni\\Downloads\\Eco Detect\"\n",
    "\n",
    "PKL_PATH     = os.path.join(OUT_DIR, \"eco_forest_rf.pkl\")\n",
    "H5_PATH      = os.path.join(OUT_DIR, \"eco_forest_mlp.h5\")     # optional (not required for plots)\n",
    "HISTORY_CSV  = os.path.join(OUT_DIR, \"history.csv\")           # created by training script\n",
    "\n",
    "ACC_PNG      = os.path.join(OUT_DIR, \"accuracy_curve.png\")\n",
    "HEAT_PNG     = os.path.join(OUT_DIR, \"residual_heatmap.png\")\n",
    "SCATTER_PNG  = os.path.join(OUT_DIR, \"pred_vs_actual.png\")\n",
    "RESID_CSV    = os.path.join(OUT_DIR, \"residuals_full.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# Split params (must match training)\n",
    "# ---------------------------\n",
    "TEST_SIZE    = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "\n",
    "# ---------- Helpers (same heuristics as training) ----------\n",
    "def pick_target_column(df: pd.DataFrame) -> str:\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    preferred = [\n",
    "        \"forest_share\", \"forest_share_percent\", \"forest_area_pct\",\n",
    "        \"forest_area_percent\", \"share\", \"value\", \"trend\"\n",
    "    ]\n",
    "    for name in preferred:\n",
    "        if name in lower:\n",
    "            return lower[name]\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if num_cols:\n",
    "        return num_cols[-1]\n",
    "    raise ValueError(\"Unable to determine target column automatically.\")\n",
    "\n",
    "def best_country_col(df: pd.DataFrame) -> Optional[str]:\n",
    "    for cand in [\"country\", \"country_name\", \"Country\", \"Country Name\", \"Entity\", \"entity\"]:\n",
    "        if cand in df.columns:\n",
    "            return cand\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "    return obj_cols[0] if obj_cols else None\n",
    "\n",
    "def best_year_col(df: pd.DataFrame) -> Optional[str]:\n",
    "    for cand in [\"year\", \"Year\", \"Time\", \"time\"]:\n",
    "        if cand in df.columns: return cand\n",
    "    for cand in [\"date\", \"Date\"]:\n",
    "        if cand in df.columns: return cand\n",
    "    return None\n",
    "\n",
    "def interpolate_target(df: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    ccol = best_country_col(df2)\n",
    "    ycol = best_year_col(df2)\n",
    "\n",
    "    # Try to coerce year-like column to numeric year\n",
    "    if ycol is not None and not np.issubdtype(df2[ycol].dtype, np.number):\n",
    "        try:\n",
    "            yr = pd.to_datetime(df2[ycol], errors=\"coerce\").dt.year\n",
    "            if yr.notna().any():\n",
    "                df2[ycol] = yr\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    before = int(df2[target].isna().sum())\n",
    "    if ccol and ycol and np.issubdtype(df2[ycol].dtype, np.number):\n",
    "        df2 = df2.sort_values([ccol, ycol])\n",
    "        df2[target] = df2.groupby(ccol, group_keys=False)[target].apply(\n",
    "            lambda s: s.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "        )\n",
    "    else:\n",
    "        df2[target] = df2[target].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "    after = int(df2[target].isna().sum())\n",
    "    logging.info(f\"[NaN repair] '{target}': {before} → {after} remaining after interpolation.\")\n",
    "    if after > 0:\n",
    "        df2 = df2.dropna(subset=[target]).reset_index(drop=True)\n",
    "        logging.info(f\"[NaN repair] Dropped {after} rows with missing target.\")\n",
    "    return df2\n",
    "\n",
    "\n",
    "# ---------- Plotters ----------\n",
    "def plot_history_curve(history_csv: str, out_png: str):\n",
    "    if not os.path.exists(history_csv):\n",
    "        logging.warning(f\"No history.csv at {history_csv} — skipping accuracy graph.\")\n",
    "        return\n",
    "    hist = pd.read_csv(history_csv)\n",
    "    plt.figure(figsize=(9,6))\n",
    "    if \"mae\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"mae\"], label=\"Train MAE\")\n",
    "    if \"val_mae\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"val_mae\"], label=\"Val MAE\")\n",
    "    if \"loss\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], np.sqrt(hist[\"loss\"]), \"--\", label=\"Train RMSE\")\n",
    "    if \"val_loss\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], np.sqrt(hist[\"val_loss\"]), \"--\", label=\"Val RMSE\")\n",
    "    plt.title(\"Training Curves (Accuracy Graph for Regression)\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Error\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=160); plt.close()\n",
    "    logging.info(f\"[PLOT] Saved accuracy graph → {out_png}\")\n",
    "\n",
    "def plot_residual_heatmap(df_val: pd.DataFrame, out_png: str):\n",
    "    \"\"\"\n",
    "    Expects df_val with columns: Country, Year (optional), y_true, y_pred, residual\n",
    "    Creates heatmap of mean residuals by Country x Year (or Country only).\n",
    "    \"\"\"\n",
    "    ccol = best_country_col(df_val)\n",
    "    ycol = best_year_col(df_val)\n",
    "\n",
    "    if ccol is None:\n",
    "        # Fallback: make a single-dimension heatmap by top-N absolute residual countries guessed from any categorical\n",
    "        logging.warning(\"No country-like column found. Aggregating by a generic categorical column if available.\")\n",
    "        cat_cols = [c for c in df_val.columns if df_val[c].dtype == \"object\"]\n",
    "        ccol = cat_cols[0] if cat_cols else None\n",
    "\n",
    "    if ccol is None:\n",
    "        logging.warning(\"No categorical column available for heatmap — skipping.\")\n",
    "        return\n",
    "\n",
    "    # Build pivot\n",
    "    if ycol is not None and ycol in df_val.columns and np.issubdtype(df_val[ycol].dtype, np.number):\n",
    "        pivot = df_val.pivot_table(index=ccol, columns=ycol, values=\"residual\", aggfunc=\"mean\")\n",
    "    else:\n",
    "        # If year absent, just a single column heatmap (mean residual per country)\n",
    "        pivot = df_val.groupby(ccol)[\"residual\"].mean().to_frame(\"mean_residual\")\n",
    "\n",
    "    # Choose top-35 by count for readability\n",
    "    counts = df_val.groupby(ccol).size().sort_values(ascending=False)\n",
    "    keep = counts.head(35).index\n",
    "    pivot = pivot.loc[pivot.index.intersection(keep)]\n",
    "\n",
    "    plt.figure(figsize=(12,9))\n",
    "    im = plt.imshow(pivot.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04, label=\"Residual (pred − true)\")\n",
    "    plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "    if isinstance(pivot, pd.DataFrame) and pivot.columns.ndim == 1:\n",
    "        plt.xticks(range(len(pivot.columns)), pivot.columns, rotation=90)\n",
    "    plt.title(\"Residual Heatmap (mean error by Country × Year)\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=160); plt.close()\n",
    "    logging.info(f\"[PLOT] Saved residual heatmap → {out_png}\")\n",
    "\n",
    "def plot_pred_vs_actual(y_true: np.ndarray, y_pred: np.ndarray, out_png: str):\n",
    "    lim_min = float(min(y_true.min(), y_pred.min()))\n",
    "    lim_max = float(max(y_true.max(), y_pred.max()))\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.scatter(y_true, y_pred, s=18, alpha=0.7)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], \"r--\", linewidth=1.5)\n",
    "    plt.xlabel(\"True\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Predicted vs. True\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=160); plt.close()\n",
    "    logging.info(f\"[PLOT] Saved predicted vs actual → {out_png}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(PKL_PATH):\n",
    "        raise FileNotFoundError(f\"Missing sklearn pipeline: {PKL_PATH}. Train first.\")\n",
    "\n",
    "    # 1) Accuracy graph from Keras history (if present)\n",
    "    plot_history_curve(HISTORY_CSV, ACC_PNG)\n",
    "\n",
    "    # 2) Load & clean data same as training\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "    # coerce numeric-like strings\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
    "    target = pick_target_column(df)\n",
    "    logging.info(f\"Target for plots: {target}\")\n",
    "\n",
    "    df = interpolate_target(df, target)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No data left after cleaning for plotting.\")\n",
    "\n",
    "    # 3) Rebuild split to replicate validation set\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].astype(float)\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "    # 4) Predict with saved sklearn pipeline\n",
    "    bundle = joblib.load(PKL_PATH)\n",
    "    sk_pipe = bundle if not isinstance(bundle, dict) else bundle.get(\"pipeline\", bundle)\n",
    "    y_pred = sk_pipe.predict(X_va)\n",
    "\n",
    "    # 5) Save residuals and compute metrics\n",
    "    r2  = r2_score(y_va, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, y_pred))\n",
    "    mae  = mean_absolute_error(y_va, y_pred)\n",
    "    logging.info(f\"[VAL] R2={r2:.4f} | RMSE={rmse:.4f} | MAE={mae:.4f}\")\n",
    "\n",
    "    resid_df = X_va.copy()\n",
    "    resid_df[\"y_true\"] = y_va.values\n",
    "    resid_df[\"y_pred\"] = y_pred\n",
    "    resid_df[\"residual\"] = resid_df[\"y_pred\"] - resid_df[\"y_true\"]\n",
    "    resid_df.to_csv(RESID_CSV, index=False, encoding=\"utf-8\")\n",
    "    logging.info(f\"[SAVE] Residuals CSV → {RESID_CSV}\")\n",
    "\n",
    "    # 6) Residual heatmap (Country × Year if present)\n",
    "    plot_residual_heatmap(resid_df, HEAT_PNG)\n",
    "\n",
    "    # 7) Predicted vs Actual scatter\n",
    "    plot_pred_vs_actual(y_va.values, y_pred, SCATTER_PNG)\n",
    "\n",
    "    logging.info(\"=== DONE (plots) ===\")\n",
    "    logging.info(f\"- {ACC_PNG if os.path.exists(ACC_PNG) else '(no history.csv → accuracy graph skipped)'}\")\n",
    "    logging.info(f\"- {HEAT_PNG}\")\n",
    "    logging.info(f\"- {SCATTER_PNG}\")\n",
    "    logging.info(f\"- {RESID_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a492f-af20-4ca0-b4ca-ddc6b808d18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
